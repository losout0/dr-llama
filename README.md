# Dr. Llama ğŸ¦™âš–ï¸

Seu assistente de IA para informaÃ§Ãµes sobre a legislaÃ§Ã£o brasileira.

**Dr. Llama** Ã© uma Prova de Conceito (PoC) de um assistente jurÃ­dico informativo, construÃ­do com uma arquitetura de **RAG (Retrieval-Augmented Generation)** e **Agentes de IA**. O sistema foi desenvolvido como projeto final para a disciplina de LLMs e tem como objetivo democratizar o acesso a informaÃ§Ãµes sobre as leis brasileiras de forma clara e referenciada.

âš ï¸ **Disclaimer:** Dr. Llama Ã© uma ferramenta experimental para fins informativos. NÃ£o Ã© um substituto para aconselhamento jurÃ­dico profissional.

## ğŸ“œ Ãndice

- [ğŸ¯Problema e Objetivo](#-problema-e-objetivo)
- [âœ¨Funcionalidades](#-funcionalidades)
- [ğŸ—ï¸Arquitetura](#-arquitetura)
- [ğŸš€Como Executar Localmente](#-como-executar-localmente)
  - [PrÃ©-requisitos](#-prÃ©-requisitos)
  - [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
  - [Executando com Docker](#-executando-com-docker)
- [ğŸ“‚Estrutura do RepositÃ³rio](#-estrutura-do-repositÃ³rio)
- [ğŸ“ŠAvaliaÃ§Ã£o](#-avaliaÃ§Ã£o)
- [âš–ï¸LimitaÃ§Ãµes Ã‰ticas e de SeguranÃ§a](#-limitaÃ§Ãµes-Ã©ticas-e-de-seguranÃ§a)
- [ğŸ—ºï¸Roadmap (PrÃ³ximos Passos)](#-roadmap-prÃ³ximos-passos)
- [ğŸ“„LicenÃ§a](#-licenÃ§a)

## ğŸ¯ Problema e Objetivo

O acesso Ã  informaÃ§Ã£o jurÃ­dica no Brasil Ã© um desafio para o cidadÃ£o comum. A linguagem tÃ©cnica e a estrutura complexa das leis dificultam a compreensÃ£o de direitos e deveres bÃ¡sicos.

O objetivo do **Dr. Llama** Ã© mitigar esse problema, oferecendo uma interface conversacional que responde a perguntas sobre os direitos do consumidor com base em fontes oficiais. O sistema utiliza tÃ©cnicas de RAG para evitar alucinaÃ§Ãµes e garantir que todas as respostas sejam fundamentadas e citem os artigos de lei correspondentes.

## âœ¨ Funcionalidades

- ğŸ’¬ **Interface Conversacional:** Dialogue com o sistema em linguagem natural.
- ğŸ“š **Respostas Baseadas em EvidÃªncias:** As respostas sÃ£o geradas a partir de um corpus de documentos legais oficiais (ConstituiÃ§Ã£o Federal, CÃ³digo de Defesa do Consumidor, etc.).
- ğŸ”— **CitaÃ§Ãµes de Fontes:** Cada resposta inclui referÃªncias explÃ­citas aos artigos de lei utilizados, permitindo a verificaÃ§Ã£o da informaÃ§Ã£o.
- ğŸ¤– **OrquestraÃ§Ã£o com Agentes (LangGraph):** Um grafo de agentes gerencia o fluxo da conversa, desde a recuperaÃ§Ã£o da informaÃ§Ã£o atÃ© a checagem de seguranÃ§a e formataÃ§Ã£o da resposta.
- âœ… **Checagem Anti-AlucinaÃ§Ã£o:** Um agente _SelfCheck_ valida se as informaÃ§Ãµes na resposta estÃ£o de fato presentes nos documentos recuperados.
- âš™ï¸ **100% Open-Source e Local*:** Utiliza modelos de LLM open-weights (via Ollama) e bancos de vetores locais (FAISS), garantindo privacidade e total controle sobre o sistema.

## ğŸ—ï¸ Arquitetura

O Dr. Llama Ã© orquestrado pelo **LangGraph**, que coordena uma equipe de agentes especializados. O fluxo de uma pergunta Ã© o seguinte:

```mermaid
graph TD
    UI[Streamlit UI]
    SUP[Supervisor Agent]
    QEA[Query Expander Agent]
    RET[Retriever Agent]
    ANS[Answer Agent]
    SELF[Self-Check Agent]
    SAFE[Safety/Policy Agent]
    VEC[VectorStore]
    LLM[LLM via Ollama]
    UI --> SUP
    SUP --> QEA
    QEA --> RET
    RET --> VEC
    RET --> ANS
    ANS --> LLM
    ANS --> SELF
    SELF --> SAFE
    SAFE --> UI
```

- **UI (Streamlit):** Interface web onde o usuÃ¡rio interage com o sistema.
- **LangGraph Supervisor:** O "maestro" que roteia a tarefa entre os diferentes agentes com base no estado atual da conversa.
- **RetrieverAgent:** ResponsÃ¡vel por buscar os trechos de lei mais relevantes para a pergunta do usuÃ¡rio no banco de vetores FAISS.
- **AnswerAgent:** Gera uma resposta em linguagem natural, utilizando o contexto fornecido pelo RetrieverAgent e citando as fontes.
- **RephraseAgent:** Tenta reescrever a resposta em termos juridicos para dar um exemplo ao usuÃ¡rio.
- **SelfCheckAgent:** Compara a resposta gerada com os documentos originais para garantir a fidelidade e evitar a invenÃ§Ã£o de informaÃ§Ãµes.
- **SafetyAgent:** Adiciona o disclaimer legal a todas as respostas, reforÃ§ando o carÃ¡ter informativo da ferramenta.

**Stack TecnolÃ³gica:** Python, LangChain, LangGraph, Ollama (Llama 3.1 8B), FAISS, HuggingFace Embeddings (gte-small), Streamlit, Docker.

## ğŸš€ Como Executar Localmente

### PrÃ©-requisitos

- Git
- Python 3.12+
- Docker
- Ollama

### InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**

```bash
git clone https://github.com/losout0/dr-llama.git
cd dr-llama
```

2. **Configure o arquivo config/.env**

- FaÃ§a uma cÃ³pia do `.env.example` e renomeie para `.env`.
- Configure o `LLM_PROVIDER`, `LLM_MODEL` e as `API_KEYS` (Caso queira usar por chamada de API).

3. **Configure o Ollama e baixe o LLM:**

- Siga as instruÃ§Ãµes para instalar o Ollama no seu sistema.
- Baixe o modelo Llama 3.1:

```Bash
ollama pull llama3.1:8b
```

4. **Crie um ambiente virtual e instale as dependÃªncias:**

```Bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

5. **Prepare os dados e o banco de vetores:**

- Adicione os arquivos de lei (ex: constituicao.pdf, cdc.pdf) na pasta /data/raw.
- Execute o script de ingestÃ£o para criar o Ã­ndice FAISS:

```Bash
python ingest/ingest_data.py
```

6. **Inicie a aplicaÃ§Ã£o:**

```Bash
streamlit run app/app.py
```

Abra seu navegador em `http://localhost:8501`.

**Executando com Docker**
ApÃ³s clonar o repositÃ³rio e rodar o script de ingestÃ£o (passos 1 e 4), vocÃª pode construir e executar o container Docker:

```Bash
# Construa a imagem
docker build -t dr-llama .
```

```bash
# Execute o container
docker run -p 8501:8501 dr-llama
```

### ğŸ“‚ Estrutura do RepositÃ³rio

```bash
/dr-llama
â”œâ”€â”€ app/                    # AplicaÃ§Ã£o Streamlit (front-end)
â”‚   â””â”€â”€ app.py      
â”œâ”€â”€ config/                 # ConfiguraÃ§Ãµes para a geraÃ§Ã£o da instÃ¢ncia LLM
â”‚   â””â”€â”€ .env      
â”œâ”€â”€ data/                   # Dados brutos (PDF/HTML do CDC) e vetores indexados
â”‚   â””â”€â”€ raw/      
â”œâ”€â”€ eval/                   # Scripts, perguntas-teste e relatÃ³rios de avaliaÃ§Ã£o
â”‚   â”œâ”€â”€ test_questions.json
â”‚   â”œâ”€â”€ evaluate_rag.py
â”‚   â””â”€â”€ evaluation/
â”‚       â””â”€â”€ latest          # Resultados da Ãºltima anÃ¡lise
â”œâ”€â”€ ingest/                 # Scripts e utilitÃ¡rios de ingestÃ£o e indexaÃ§Ã£o de dados
â”‚   â””â”€â”€ ingest_data.py      
â”œâ”€â”€ notebooks/              # Notebook para testes manuais
â”‚   â””â”€â”€ test_agents.ipynb
â”œâ”€â”€ src/                    # CÃ³digo-fonte principal (pipelines, agentes, utilitÃ¡rios)
â”‚   â”œâ”€â”€ agents/      
â”‚   â”œâ”€â”€ utils/      
â”‚   â””â”€â”€ graph.py
â”œâ”€â”€ .gitignore              
â”œâ”€â”€ Dockerfile              # ContainerizaÃ§Ã£o do ambiente
â”œâ”€â”€ LICENSE                 # LicenÃ§a aberta (MIT)
â””â”€â”€ README.md               # Este arquivo
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
```

### ğŸ“Š AvaliaÃ§Ã£o

A qualidade do sistema Ã© medida utilizando o framework **RAGAS**. Nosso processo de avaliaÃ§Ã£o inclui:

- Um conjunto de **20 perguntas** de teste com respostas de referÃªncia, localizadas em `eval/test_questions.json`.
- MÃ©tricas principais: `Faithfulness`, `Answer Relevancy`, `Context Precision` e `Context Recall`.
- Os resultados detalhados e a anÃ¡lise crÃ­tica da performance estÃ£o disponÃ­veis no relatÃ³rio `eval/report.md`.

### âš–ï¸ LimitaÃ§Ãµes Ã‰ticas e de SeguranÃ§a

- **NÃƒO Ã© Aconselhamento JurÃ­dico:** Dr. Llama Ã© uma ferramenta de informaÃ§Ã£o, nÃ£o um consultor legal. As respostas nÃ£o criam uma relaÃ§Ã£o advogado-cliente.
- **InformaÃ§Ã£o Potencialmente Desatualizada**: O corpus de conhecimento Ã© estÃ¡tico e baseado nos documentos fornecidos na data da ingestÃ£o. Leis podem ser alteradas.
- **Sem Garantia de PrecisÃ£o**: Embora utilize RAG para mitigar alucinaÃ§Ãµes, erros de interpretaÃ§Ã£o ou recuperaÃ§Ã£o podem ocorrer. Sempre verifique as fontes citadas.
- **Complexidade do Caso**: O sistema nÃ£o considera as nuances e particularidades de um caso real, que sÃ£o essenciais para uma orientaÃ§Ã£o jurÃ­dica adequada.

### ğŸ—ºï¸ Roadmap (PrÃ³ximos Passos)

- [ ] **Expandir o Corpus:** Incluir mais documentos legais (CLT, CÃ³digo Civil, etc.).
- [ ] **Melhorar o Retrieval:** Implementar tÃ©cnicas de re-ranking (Cross-Encoders) para melhorar a relevÃ¢ncia dos documentos.
- [ ] **AvaliaÃ§Ã£o ContÃ­nua:** Criar um workflow de CI/CD que rode a suÃ­te de avaliaÃ§Ã£o a cada mudanÃ§a no cÃ³digo.
- [ ] **Deploy:** Publicar a aplicaÃ§Ã£o em uma plataforma como Hugging Face Spaces ou Streamlit Community Cloud.

### ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a APACHE 2.0. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.
